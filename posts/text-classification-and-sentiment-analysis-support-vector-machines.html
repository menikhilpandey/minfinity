<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <title>minfinity | Text Classification and Sentiment Analysis : Support Vector Machines</title>
  <meta name="description" content="Discussion of SVM Classifier in context of Natural Language Processing and Sentiment Analysis">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <meta property="og:title" content="Text Classification and Sentiment Analysis : Support Vector Machines">
  <meta property="og:type" content="website">
  <meta property="og:url" content="http://blog.nikhilpandey.me/posts/text-classification-and-sentiment-analysis-support-vector-machines">
  <meta property="og:description" content="Discussion of SVM Classifier in context of Natural Language Processing and Sentiment Analysis">
  <meta property="og:site_name" content="minfinity">
  <meta property="og:image" content="http://blog.nikhilpandey.me/assets/post-images/nlp-word-cloud.jpg">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:url" content="http://blog.nikhilpandey.me/posts/text-classification-and-sentiment-analysis-support-vector-machines">
  <meta name="twitter:title" content="Text Classification and Sentiment Analysis : Support Vector Machines">
  <meta name="twitter:description" content="Discussion of SVM Classifier in context of Natural Language Processing and Sentiment Analysis">
  <meta name="twitter:image" content="http://blog.nikhilpandey.me/assets/post-images/nlp-word-cloud.jpg">

  <link rel="apple-touch-icon" href="/assets/apple-touch-icon.png">
  <link href="http://blog.nikhilpandey.me/feed.xml" type="application/rss+xml" rel="alternate" title="minfinity Last 10 blog posts" />

  
    <link type="text/css" rel="stylesheet" href="/assets/light.css">
  
</head>

<body>
  <main role="main">
    <div class="grid grid-centered">
      <div class="grid-cell">
        <nav class="header-nav reveal">
  <a href="/" class="header-logo" title="minfinity">minfinity</a>
  <ul class="header-links">
    
      <li>
        <a href="https://twitter.com/menikhilpandey" target="_blank" title="Twitter">
          <span class="icon icon-social-twitter"></span>
        </a>
      </li>
    
    
      <li>
        <a href="https://www.facebook.com/menikhilpandey" target="_blank" title="Facebook">
          <span class="icon icon-social-facebook"></span>
        </a>
      </li>
    
    
      <li>
        <a href="https://github.com/menikhilpandey" target="_blank" title="GitHub">
          <span class="icon icon-social-github"></span>
        </a>
      </li>
    
    
    
    
      <li>
        <a href="https://www.linkedin.com/in/menikhilpandey" target="_blank" title="LinkedIn">
          <span class="icon icon-social-linkedin"></span>
        </a>
      </li>
    
    
    
      <li>
        <a href="mailto:contact@nikhilpandey.me" target="_blank" title="Email">
          <span class="icon icon-at"></span>
        </a>
      </li>
    
    
      <li>
        <a href="/feed.xml" target="_blank" title="RSS">
          <span class="icon icon-social-rss"></span>
        </a>
      </li>
    
  </ul>
</nav>

        <article class="article reveal">
          <header class="article-header">
            <h1>Text Classification and Sentiment Analysis : Support Vector Machines</h1>
            <p>Discussion of SVM Classifier in context of Natural Language Processing and Sentiment Analysis</p>
            <div class="article-list-footer">
              <span class="article-list-date">
                March 19, 2017
              </span>
              <span class="article-list-divider">-</span>
              <span class="article-list-minutes">
                
                
                  3 minute read
                
              </span>
              <span class="article-list-divider">-</span>
              <div class="article-list-tags">
                
                  <a href="/tag/machine-learning">machine-learning</a>
                
                  <a href="/tag/sentiment-analytics">sentiment-analytics</a>
                
              </div>
            </div>
          </header>

          <div class="article-content">
            <p>Although it is not immediatly obvious from the name, the SVM algorithm is a ‘simple’ linear classification/regression algorithm. It tries to find a hyperplane which seperates the data in two classes as optimally as possible.</p>

<p>Here as optimally as possible means that as much points as possible of label A should be seperated to one side of the hyperplane and as points of label B to the other side, while maximizing the distance of each point to this hyperplane.</p>

<p><a href="/assets/post-images/NLP-SVM/svm-max-sep-hyperplane-with-margin.jpg" class="fluidbox-trigger">
  <img src="/assets/post-images/NLP-SVM/svm-max-sep-hyperplane-with-margin.jpg" alt="SVM Hyperplane" />
</a></p>

<p>In the image above we can see this illustrated for the example of points plotted in 2D-space. The set of points are labeled  with two categories (illustrated here with black and white points) and SVM chooses the hypeplane that maximizes the margin between the two classes. This hyperplane is given by</p>

<p><a href="/assets/post-images/NLP-SVM/1.svg" class="fluidbox-trigger">
  <img src="/assets/post-images/NLP-SVM/1.svg" alt="Equation" />
</a></p>

<p>where <strong>x<sub>i</sub></strong> = <strong>(x<sub>i1</sub>, x<sub>i2</sub>, .. , x<sub>in</sub> )</strong> is a n-dimensional input vector, y<sub>i</sub> is its output value, <strong>w</strong> = <strong>(w<sub>1</sub>, w<sub>2</sub>, .. , w<sub>n</sub> )</strong> is the weight vector (the normal vector) defining the hyperplane and the <strong><em>alpha<sub>i</sub></em></strong> terms are the Lagrangian multipliers.</p>

<p>Once the hyperplane is constructed (the vector <strong><em>w</em></strong> is defined) with a training set, the class of any other input vector <strong><em>x<sub>i</sub></em></strong> can be determined:
if <strong><em>w.x<sub>i</sub> + b &gt;= 0</em></strong> then it belongs to the positive class (the class we are interested in), otherwise it belongs to the negative class (all of the other classes).</p>

<p>We can already see this leads to two interesting questions:</p>

<ol>
  <li>
    <p>SVM only seems to work when the two classes are linearly separable. How can we deal with non-linear datasets? Here I feel the urge to point out that the Naive Bayes and Maximum Entropy are linear classifiers as well and most text documents will be linear. Our training example of Amazon book reviews will be linear as well. But an explanation of the SVM system will not be complete without an explanation of Kernel functions.</p>
  </li>
  <li>
    <p>SVM only seems to be able to separate the dataset into two classes? How can we deal with datasets with more than two classes. For Sentiment Classification we have for example three classes (positive, neutral, negative) and for Topic Classification we can have even more than that.</p>
  </li>
</ol>

<h3 id="kernel-functions">Kernel Functions:</h3>
<p>The classical SVM system requires that the dataset is linearly separable, i.e. there is a single hyperplane which can separate the two classes. For non-linear datasets a Kernel function is used to map the data to a higher dimensional space in which it is linearly separable. This video gives a good illustation of such a mapping. In this higher dimensional feature space, the classical SVM system can then be used to construct a hyperplane.</p>

<h3 id="multiclass-classification">Multiclass classification:</h3>
<p>The classical SVM system is a binary classifier, meaning that it can only separate the dataset into  two classes. To deal with datasets with more than two classes usually the dataset is reduced to a binary class dataset with which the SVM can work. There are two approaches for decomposing a multiclass classification problem to a binary classification problem: the one-vs-all and one-vs-one approach.
In the one-vs-all approach one SVM Classifier is build per class. This Classifier takes that one class as the positive class and the rest of the classes as the negative class. A datapoint is then only classified within a specific class if it is accepted by that Class’ Classifier and rejected by all other classifiers. Although this can lead to accurate results (if the dataset is clustered), a lot of datapoints can also be left unclassified (if the dataset is not clustered).
In the one-vs-one approach, you build one SVM Classifier per chosen pair of classes. Since there are <strong>0.5N(N-1)</strong> possible pair combinations for a set of N classes, this means you have to construct more Classifiers. Datapoints are then categorized in the class for which they have received the most points.</p>

<p>In our example, there are only three classes (positive, neutral, negative) so there is no real difference between these two approaches. In both approaches we have to construct two hyperplanes; positive vs the rest and negative vs the rest.</p>

          </div>

          <div class="article-share">
            
            <a href="" title="Share on Twitter" onclick="window.open('https://twitter.com/home?status=Text Classification and Sentiment Analysis : Su... - http://blog.nikhilpandey.me/posts/text-classification-and-sentiment-analysis-support-vector-machines by @menikhilpandey', 'newwindow', 'width=500, height=225'); return false;">
              <span class="icon icon-social-twitter"></span>
            </a>
            <a href="" title="Share on Facebook" onclick="window.open('https://www.facebook.com/sharer/sharer.php?u=http://blog.nikhilpandey.me/posts/text-classification-and-sentiment-analysis-support-vector-machines', 'newwindow', 'width=500, height=500'); return false;">
              <span class="icon icon-social-facebook"></span>
            </a>
            <a href="" title="Share on Google+" onclick="window.open('https://plus.google.com/share?url=http://blog.nikhilpandey.me/posts/text-classification-and-sentiment-analysis-support-vector-machines', 'newwindow', 'width=550, height=400'); return false;">
              <span class="icon icon-social-googleplus"></span>
            </a>
          </div>

          
        </article>
        <footer class="footer reveal">
  <p>
    Powered by Jekyll.<br>
    © 2016 | <a href="http://nikhilpandey.me">Nikhil Pandey</a>.
  </p>
</footer>

      </div>
    </div>
  </main>
  <script type="text/javascript" src="/assets/vendor.js"></script>
<script type="text/javascript" src="/assets/application.js"></script>

<script src="https://ajax.googleapis.com/ajax/libs/webfont/1.6.16/webfont.js"></script>
<script>
  WebFont.load({
    google: {
      families: ['Cormorant Garamond:700', 'Lato:300,400,700']
    }
  });
</script>


  <script>
    window.ga=function(){ga.q.push(arguments)};ga.q=[];ga.l=+new Date;
    ga('create','UA-88810479-1','auto');ga('send','pageview')
  </script>
  <script src="https://www.google-analytics.com/analytics.js" async defer></script>


</body>
</html>
